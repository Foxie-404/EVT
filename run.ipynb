{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spr-Aachen/Easy-Voice-Toolkit/blob/main/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Terms of Use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**Please solve the authorization problem of the dataset on your own. You shall be solely responsible for any problems caused by the use of non-authorized datasets for training and all consequences thereof.The repository and its maintainer have nothing to do with the consequences!**\n",
        "\n",
        "1. This project is established for academic exchange purposes only and is intended for communication and learning purposes. It is not intended for production environments.\n",
        "2. Any videos based on Easy Voice Toolkit that are published on video platforms must clearly indicate in the description that they are used for voice changing and specify the input source of the voice or audio, for example, using videos or audios published by others and separating the vocals as input source for conversion, which must provide clear original video links. If your own voice or other synthesized voices from other commercial vocal synthesis software are used as the input source for conversion, you must also explain it in the description.\n",
        "3. You shall be solely responsible for any infringement problems caused by the input source. When using other commercial vocal synthesis software as input source, please ensure that you comply with the terms of use of the software. Note that many vocal synthesis engines clearly state in their terms of use that they cannot be used for input source conversion.\n",
        "4. Continuing to use this project is deemed as agreeing to the relevant provisions stated in this repository README. This repository README has the obligation to persuade, and is not responsible for any subsequent problems that may arise.\n",
        "5. If you distribute this repository's code or publish any results produced by this project publicly (including but not limited to video sharing platforms), please indicate the original author and code source (this repository).\n",
        "6. If you use this project for any other plan, please contact and inform the author of this repository in advance. Thank you very much."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Colab"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 防止断连<br>Prevent Disconnection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EblwyDLicmnp"
      },
      "source": [
        "按住 Ctrl+Shift 再按下 I 呼出浏览器的开发工具，于控制台内输入以下内容并回车\n",
        "```\n",
        "function ConnectButton()\n",
        "{\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 使用GPU<br>Use GPU"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "找到上方菜单栏“代码执行程序”——>“更改运行时类型”——>\"硬件加速器\"，选择GPU"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 克隆仓库<br>Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone --recurse-submodules https://github.com/Spr-Aachen/Easy-Voice-Toolkit.git\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "!sed -i '10s/False/True/' ./EVT_Core/GPT_SoVITS/config.py"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 安装依赖<br>Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get update``\n",
        "!apt-get install portaudio19-dev\n",
        "!pip3 install -r requirements.txt\n",
        "#!pip3 install --force-reinstall --yes torch torchvision torchaudio\n",
        "!/usr/local/bin/pip install ipykernel\n",
        "'''\n",
        "!apt-get install python3.9\n",
        "!cp -r /usr/local/lib/python3.10/dist-packages /usr/local/lib/python3.9/\n",
        "'''\n",
        "#exit() # Enable this only when you decide to delete the runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 下载模型<br>Download Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get UVR5 models\n",
        "!mkdir -p /content/models/download/uvr5\n",
        "%cd /content/models/download/uvr5\n",
        "!git clone https://huggingface.co/Delik/uvr5_weights\n",
        "!mv /content/models/download/uvr5/uvr5_weights/* /content/models/download/uvr5/\n",
        "# get VPR models\n",
        "!mkdir -p /content/models/download/VPR\n",
        "%cd /content/models/download/VPR\n",
        "!git clone https://huggingface.co/SprAachen/VPR\n",
        "!mv /content/models/download/VPR/VPR/* /content/models/download/VPR\n",
        "# get Whisper models\n",
        "!mkdir -p /content/models/download/Whisper\n",
        "%cd /content/models/download/Whisper\n",
        "!git clone https://huggingface.co/SprAachen/Whisper\n",
        "!mv /content/models/download/Whisper/Whisper/* /content/models/download/Whisper\n",
        "# get GPT-SoVITS pretrains\n",
        "!mkdir -p /content/models/download/GPT-SoVITS\n",
        "%cd /content/models/download/GPT-SoVITS\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS\n",
        "!mv /content/models/download/GPT-SoVITS/GPT-SoVITS/* /content/models/download/GPT-SoVITS/\n",
        "# get VITS pretrains\n",
        "# **暂无，抱歉 Not Available**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 装载硬盘<br>Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 准备文件<br>Prepare Files"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "检查是否已将需要处理的文件上传到了 https://drive.google.com/drive/my-drive 中"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Tools"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 音频处理 AudioProcessor\n",
        "将媒体文件批量转换为音频文件然后自动切除音频的静音部分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.AudioProcessor.process import Audio_Processing\n",
        "\n",
        "#@markdown **媒体输入目录**：需要输出为音频文件的媒体文件的目录\n",
        "Media_Dir_Input: str = '/content/drive/MyDrive/%MediaInput%'   #@param {type:\"string\"}\n",
        "#@markdown **媒体输出格式**：需要输出为的音频文件的格式\n",
        "Media_Format_Output: str = 'wav'   #@param [\"flac\", \"wav\", \"mp3\", \"aac\", \"ogg\", \"m4a\", \"wma\", \"aiff\", \"au\"]\n",
        "#@markdown **启用降噪**：音频中的噪声将被降噪处理\n",
        "Denoise_Audio: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **降噪目标**：选择在降噪时要保留的声音对象\n",
        "Denoise_Target: str = '人声'   #@param [\"人声\", \"背景声\"]\n",
        "#@markdown **启用静音切除**：音频中的静音部分将被切除\n",
        "Slice_Audio: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **均方根阈值 (db)**：低于该阈值的片段将被视作静音进行处理，若有降噪需求可以增加该值\n",
        "RMS_Threshold: float = -40.   #@param {type:\"number\"}\n",
        "#@markdown **跳跃大小 (ms)**：每个RMS帧的长度，增加该值能够提高分割精度但会减慢进程\n",
        "Hop_Size: int = 10   #@param {type:\"integer\"}\n",
        "#@markdown **最小静音间隔 (ms)**：静音部分被分割成的最小长度，若音频只包含短暂中断可以减小该值（注意：这个值必须小于 Audio Length Min，大于 Hop Size）\n",
        "Silent_Interval_Min: int = 300   #@param {type:\"integer\"}\n",
        "#@markdown **最大静音长度 (ms)**：被分割的音频周围保持静音的最大长度（提示：这个值无需完全对应被分割音频中的静音长度。算法将自行检索最佳的分割位置）\n",
        "Silence_Kept_Max: int = 1000   #@param {type:\"integer\"}\n",
        "#@markdown **最小音频长度 (ms)**：每个被分割的音频片段所需的最小长度\n",
        "Audio_Length_Min: int = 3000   #@param {type:\"integer\"}\n",
        "#@markdown **输出采样率**：输出音频所拥有的采样率，若维持不变则保持'None'即可\n",
        "SampleRate: int = None   #@param [\"None\", 44100, 48000, 96000, 192000]\n",
        "#@markdown **输出采样位数**：输出音频所拥有的采样位数，若维持不变则保持'None'即可\n",
        "SampleWidth: int = None   #@param [\"None\", 8, 16, 24, 32]\n",
        "#@markdown **合并声道**：将输出音频的声道合并为单声道\n",
        "ToMono: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **输出目录**：用于保存最后生成的音频文件的目录\n",
        "Media_Dir_Output: str = f'/content/drive/MyDrive/EVT/音频处理结果/{date.today()}'   #@param {type:\"string\"}\n",
        "\n",
        "AudioConvertandSlice = Audio_Processing(\n",
        "    Media_Dir_Input,\n",
        "    Media_Format_Output,\n",
        "    SampleRate if SampleRate != \"None\" else None,\n",
        "    SampleWidth if SampleWidth != \"None\" else None,\n",
        "    ToMono,\n",
        "    Denoise_Audio,\n",
        "    '/content/models/download/uvr5/HP5_only_main_vocal.pth',\n",
        "    Denoise_Target,\n",
        "    Slice_Audio,\n",
        "    RMS_Threshold,\n",
        "    Audio_Length_Min,\n",
        "    Silent_Interval_Min,\n",
        "    Hop_Size,\n",
        "    Silence_Kept_Max,\n",
        "    Path(Media_Dir_Output).parent.__str__(),\n",
        "    Path(Media_Dir_Output).name\n",
        ")\n",
        "AudioConvertandSlice.processAudio()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 语音识别 VoiceIdentifier\n",
        "在不同说话人的音频中批量筛选出属于同一说话人的音频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.VPR.infer import Voice_Contrasting\n",
        "\n",
        "#@markdown **音频输入目录**：需要进行语音识别筛选的音频文件的目录\n",
        "Audio_Dir_Input: str = '/content/drive/MyDrive/%...%'   #@param {type:\"string\"}\n",
        "#@markdown **目标人物与音频**：目标人物的名字及其语音文件的所在路径\n",
        "StdAudioSpeaker: dict = {'%SpeakerName%': '/content/drive/MyDrive/%StdAudio.wav%'}   #@param {type:\"raw\"}\n",
        "#@markdown **判断阈值**：判断是否为同一人的阈值，若参与比对的说话人声音相识度较高可以增加该值\n",
        "DecisionThreshold: float = 0.75   #@param {type:\"number\"}\n",
        "#@markdown **音频长度**：用于预测的音频长度\n",
        "Duration_of_Audio: float = 3.00   #@param {type:\"number\"}\n",
        "#@markdown **输出目录**：用于保存最后生成的结果文件的目录\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/语音识别结果/{date.today()}'   #@param {type:\"string\"}\n",
        "#@markdown **识别结果文本名**：用于保存最后生成的记录音频文件与对应说话人的txt文件的名字\n",
        "AudioSpeakersDataName: str = 'Recgonition'   #@param {type:\"string\"}\n",
        "\n",
        "import os, shutil\n",
        "def ASRResult_Update(AudioSpeakersData_Path: str, MoveToDst: str):\n",
        "    os.makedirs(MoveToDst, exist_ok = True) if Path(MoveToDst).exists() == False else None\n",
        "    with open(AudioSpeakersData_Path, mode = 'w', encoding = 'utf-8') as AudioSpeakersData:\n",
        "        AudioSpeakers = AudioSpeakersData.readlines()\n",
        "        Lines = []\n",
        "        for AudioSpeaker in AudioSpeakers:\n",
        "            Audio, Speaker = AudioSpeaker.split('|', maxsplit = 1)\n",
        "            if Speaker.strip() != '':\n",
        "                MoveToDst_Sub = Path(MoveToDst).joinpath(Speaker).as_posix()\n",
        "                os.makedirs(MoveToDst_Sub, exist_ok = True) if Path(MoveToDst_Sub).exists() == False else None\n",
        "                Audio_Dst = Path(MoveToDst_Sub).joinpath(Path(Audio).name).as_posix()\n",
        "                shutil.copy(Audio, MoveToDst_Sub) if not Path(Audio_Dst).exists() else None\n",
        "                Lines.append(f\"{Audio_Dst}|{Speaker}\\n\")\n",
        "        AudioSpeakersData.writelines(Lines)\n",
        "\n",
        "AudioContrastInference = Voice_Contrasting(\n",
        "    StdAudioSpeaker,\n",
        "    Audio_Dir_Input,\n",
        "    '/content/models/download/VPR/Ecapa-Tdnn_spectrogram.pth',\n",
        "    'Ecapa-Tdnn',\n",
        "    'spectrogram',\n",
        "    DecisionThreshold,\n",
        "    Duration_of_Audio,\n",
        "    Path(Output_Dir).parent.__str__(),\n",
        "    Path(Output_Dir).name,\n",
        "    AudioSpeakersDataName\n",
        ")\n",
        "AudioContrastInference.getModel()\n",
        "AudioContrastInference.inference()\n",
        "ASRResult_Update(\n",
        "    Path(Output_Dir).joinpath(AudioSpeakersDataName) + \".txt\",\n",
        "    Output_Dir\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 语音转录 VoiceTranscriber\n",
        "将语音文件的内容批量转换为带时间戳的文本并以字幕文件的形式保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.Whisper.transcribe import Voice_Transcribing\n",
        "\n",
        "#@markdown **音频目录**：需要将语音内容转为文字的wav文件的目录\n",
        "Audio_Dir: str = '/content/drive/MyDrive/%EVT/语音识别结果/...%'   #@param {type:\"string\"}\n",
        "#@markdown **标注语言信息**：标注音频中说话人所使用的语言，若用于VITS数据集制作则建议启用\n",
        "Add_LanguageInfo: str = True   #@param {type:\"boolean\"}\n",
        "#@markdown **半精度训练**：主要使用半精度浮点数进行计算，若GPU不可用则忽略或禁用此项\n",
        "fp16: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **启用输出日志**：是否输出debug日志\n",
        "Verbose: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **关联上下文**：在音频之间的内容具有关联性时启用该项可以获得更好的效果，若模型陷入了失败循环则禁用此项\n",
        "Condition_on_Previous_Text: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **输出目录**：最后生成的字幕文件将会保存到该目录中\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/语音转录结果/{date.today()}'   #@param {type:\"string\"}\n",
        "\n",
        "WAVtoSRT = Voice_Transcribing(\n",
        "    '/content/models/download/Whisper/base.pt',\n",
        "    Audio_Dir,\n",
        "    Verbose,\n",
        "    Add_LanguageInfo,\n",
        "    Condition_on_Previous_Text,\n",
        "    fp16,\n",
        "    Path(Output_Dir).parent.__str__(),\n",
        "    Path(Output_Dir).name\n",
        ")\n",
        "WAVtoSRT.transcribe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPT-SoVITS数据集制作 DatasetCreator - GPT-SoVITS\n",
        "生成适用于语音模型训练的数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.GPT_SoVITS.preprocess import Dataset_Creating\n",
        "\n",
        "#@markdown **音频文件目录/语音识别结果文件路径**：音频文件的所在目录（要求按说话人分类），或者提供由语音识别得到的文本文件的所在路径\n",
        "AudioSpeakersData_Path: str = '/content/drive/MyDrive/%EVT/语音识别结果/GPT-SoVITS/...%'   #@param {type:\"string\"}\n",
        "#@markdown **字幕输入目录**：需要转为适用于模型训练的csv文件的srt文件的目录\n",
        "SRT_Dir: str = '/content/drive/MyDrive/%EVT/语音转录结果/GPT-SoVITS/...%'   #@param {type:\"string\"}\n",
        "#@markdown **输出目录**：用于保存最后生成的数据集的目录\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/数据集制作结果/GPT-SoVITS/{date.today()}'   #@param {type:\"string\"}\n",
        "#@markdown **训练集文本名**：用于保存最后生成的训练集txt文件的名字\n",
        "FileList_Name_Training: str = 'train'   #@param {type:\"string\"}\n",
        "\n",
        "SRTtoCSVandSplitAudio = Dataset_Creating(\n",
        "    SRT_Dir = SRT_Dir,\n",
        "    AudioSpeakersData_Path = AudioSpeakersData_Path,\n",
        "    Output_Root = Path(Output_Dir).parent.__str__(),\n",
        "    Output_DirName = Path(Output_Dir).name,\n",
        "    FileList_Name = FileList_Name_Training\n",
        ")\n",
        "SRTtoCSVandSplitAudio.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPT-SoVITS模型训练 VoiceTrainer - GPT-SoVITS\n",
        "训练出适用于语音合成的模型文件（若在使用过程中出现报错，可以尝试先`断开连接并删除运行时`，然后重新运行 Configure Colab 部分以及本代码块）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.GPT_SoVITS.train import train\n",
        "\n",
        "#@markdown **训练版本**\n",
        "version: str = 'v2'   #@param [\"v2\", \"v3\"]\n",
        "#@markdown **训练集文本路径**：用于提供训练集音频路径及其语音内容的训练集txt文件的路径\n",
        "fileList_path: str = '/content/drive/MyDrive/%EVT/数据集制作结果/GPT-SoVITS/train.txt%'   #@param {type:\"string\"}\n",
        "#@markdown **半精度训练**：通过混合了float16精度的训练方式减小显存占用以支持更大的批处理量\n",
        "half_precision: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **输出目录**：用于存放生成的模型和配置文件的目录，若目录中已存在模型则会将其视为检查点（注意：当目录中存在多个模型时，编号最大的会被选为检查点）\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/模型训练结果/GPT-SoVITS/{date.today()}'   #@param {type:\"string\"}\n",
        "\n",
        "PreprocessandTrain = train(\n",
        "    version,\n",
        "    fileList_path,\n",
        "    modelDir_bert = '/content/models/download/GPT-SoVITS/chinese-roberta-wwm-ext-large',\n",
        "    modelDir_hubert = '/content/models/download/GPT-SoVITS/chinese-hubert-base',\n",
        "    modelPath_gpt = '/content/models/download/GPT-SoVITS/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt',\n",
        "    modelPath_sovitsG = '/content/models/download/GPT-SoVITS/s2G488k.pth',\n",
        "    modelPath_sovitsD = '/content/models/download/GPT-SoVITS/s2D488k.pth',\n",
        "    half_precision = half_precision,\n",
        "    if_grad_ckpt = False,\n",
        "    lora_rank = 32,\n",
        "    Output_Root = Path(Output_Dir).parent.__str__(),\n",
        "    Output_DirName = Path(Output_Dir).name,\n",
        "    Output_LogDir = \"/content/drive/MyDrive/EVT/log\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPT-SoVITS语音合成 VoiceConverter - GPT-SoVITS\n",
        "将文字转为语音并生成音频文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from EVT_Core.GPT_SoVITS.infer_webui import infer\n",
        "\n",
        "#@markdown **推理版本**\n",
        "version: str = 'v2'   #@param [\"v2\", \"v3\"]\n",
        "#@markdown **半精度推理**：通过混合了float16精度的推理方式减小显存占用以支持更大的批处理量\n",
        "half_precision: bool = True   #@param {type:\"boolean\"}\n",
        "# #@markdown **启用批处理推理**：通过批处理推理的方式减小显存占用以支持更大的批处理量\n",
        "# batched_infer: bool = True   #@param {type:\"boolean\"}\n",
        "\n",
        "VoiceConverting = infer(\n",
        "    version,\n",
        "    sovits_path = '/content/models/download/GPT-SoVITS/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt',\n",
        "    path_sovits_v3 = '/content/models/download/GPT-SoVITS/s2Gv3.pth',\n",
        "    gpt_path = '/content/models/download/GPT-SoVITS/s2G488k.pth',\n",
        "    cnhubert_base_path = '/content/models/download/GPT-SoVITS/chinese-hubert-base',\n",
        "    bert_path = '/content/models/download/GPT-SoVITS/chinese-roberta-wwm-ext-large',\n",
        "    bigvgan_path = '/content/models/download/GPT-SoVITS/models--nvidia--bigvgan_v2_24khz_100band_256x',\n",
        "    half_precision = half_precision,\n",
        "    # batched_infer = batched_infer,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VITS2数据集制作 DatasetCreator - VITS2\n",
        "生成适用于语音模型训练的数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.VITS.preprocess import Dataset_Creating\n",
        "\n",
        "#@markdown **音频文件目录/语音识别结果文件路径**：音频文件的所在目录（要求按说话人分类），或者提供由语音识别得到的文本文件的所在路径\n",
        "AudioSpeakersData_Path: str = '/content/drive/MyDrive/%EVT/语音识别结果/VITS/...%'   #@param {type:\"string\"}\n",
        "#@markdown **字幕输入目录**：需要转为适用于模型训练的csv文件的srt文件的目录\n",
        "SRT_Dir: str = '/content/drive/MyDrive/%EVT/语音转录结果/VITS/...%'   #@param {type:\"string\"}\n",
        "#@markdown **添加辅助数据**：添加用以辅助训练的数据集，若当前语音数据的质量/数量较低则建议启用\n",
        "Add_AuxiliaryData: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **辅助数据文本路径**：辅助数据集的文本的所在路径\n",
        "AuxiliaryData_Path: str = '/content/drive/MyDrive/%EVT/AuxiliaryData/VITS/AuxiliaryData.txt%'   #@param {type:\"string\"}\n",
        "#@markdown **添加其它语言辅助数据**：启用以允许添加与当前数据集语言不匹配的辅助数据\n",
        "Add_UnmatchedLanguage: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **采样率 (HZ)**：数据集所要求的音频采样率，若维持不变则保持'None'即可\n",
        "SampleRate: int = 22050   #@param [\"None\", 22050, 44100, 48000, 96000, 192000]\n",
        "#@markdown **采样位数**：数据集所要求的音频采样位数，若维持不变则保持'None'即可\n",
        "SampleWidth: str = '16'   #@param [\"None\", 8, 16, 24, 32]\n",
        "#@markdown **合并声道**：将输出音频的声道合并为单声道\n",
        "ToMono: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **训练集占比**：划分给训练集的数据在数据集中所占的比例\n",
        "TrainRatio: float = 0.7   #@param {type:\"number\"}\n",
        "#@markdown **输出目录**：用于保存最后生成的数据集的目录\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/数据集制作结果/VITS/{date.today()}'   #@param {type:\"string\"}\n",
        "#@markdown **训练集文本名**：用于保存最后生成的训练集txt文件的名字\n",
        "FileList_Name_Training: str = 'train'   #@param {type:\"string\"}\n",
        "#@markdown **验证集文本名**：用于保存最后生成的验证集txt文件的名字\n",
        "FileList_Name_Validation: str = 'Val'   #@param {type:\"string\"}\n",
        "\n",
        "SRTtoCSVandSplitAudio = Dataset_Creating(\n",
        "    SRT_Dir,\n",
        "    AudioSpeakersData_Path,\n",
        "    SampleRate if SampleRate != \"None\" else None,\n",
        "    SampleWidth if SampleWidth != \"None\" else None,\n",
        "    ToMono,\n",
        "    Add_AuxiliaryData,\n",
        "    AuxiliaryData_Path,\n",
        "    Add_UnmatchedLanguage,\n",
        "    TrainRatio,\n",
        "    Path(Output_Dir).parent.__str__(),\n",
        "    Path(Output_Dir).name,\n",
        "    FileList_Name_Training,\n",
        "    FileList_Name_Validation\n",
        ")\n",
        "SRTtoCSVandSplitAudio.run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VITS2模型训练 VoiceTrainer - VITS2\n",
        "训练出适用于语音合成的模型文件（若在使用过程中出现报错，可以尝试先`断开连接并删除运行时`，然后重新运行 Configure Colab 部分以及本代码块）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.VITS.train import train\n",
        "\n",
        "#@markdown **训练集文本路径**：用于提供训练集音频路径及其语音内容的训练集txt文件的路径\n",
        "FileList_Path_Training: str = '/content/drive/MyDrive/%EVT/数据集制作结果/VITS/train.txt%'   #@param {type:\"string\"}\n",
        "#@markdown **验证集文本路径**：用于提供验证集音频路径及其语音内容的验证集txt文件的路径\n",
        "FileList_Path_Validation: str = '/content/drive/MyDrive/%EVT/数据集制作结果/VITS/Val.txt%'   #@param {type:\"string\"}\n",
        "#@markdown **迭代次数**：将全部样本完整迭代一轮的次数\n",
        "Epochs: int = 300   #@param {type:\"integer\"}\n",
        "#@markdown **批处理量**：每轮迭代中单位批次的样本数量（注意：最好设置为2的幂次）\n",
        "Batch_Size: int = 16   #@param {type:\"integer\"}\n",
        "#@markdown **使用预训练模型**：使用预训练模型（底模），注意其载入优先级高于检查点\n",
        "Use_PretrainedModels: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **[可选]预训练G模型路径**：预训练生成器（Generator）模型的路径\n",
        "Model_Path_Pretrained_G: str = '/content/drive/MyDrive/%EVT/Pretrained Models/standard_G.pth%'   #@param {type:\"string\"}\n",
        "#@markdown **[可选]预训练D模型路径**：预训练判别器（Discriminator）模型的路径\n",
        "Model_Path_Pretrained_D: str = '/content/drive/MyDrive/%EVT/Pretrained Models/standard_D.pth%'   #@param {type:\"string\"}\n",
        "#@markdown **[可选]保留原说话人**：保留底模中原有的说话人，请保证每个原角色至少有一两条音频参与训练\n",
        "Keep_Original_Speakers: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **[可选]配置加载路径**：用于加载底模人物信息的配置文件的所在路径\n",
        "Config_Path_Load: str = '/content/drive/MyDrive/%EVT/Pretrained Models/standard_Config.json%'   #@param {type:\"string\"}\n",
        "#@markdown **进程数量**：进行数据加载时可并行的进程数量\n",
        "Num_Workers: int = 8   #@param {type:\"integer\"}\n",
        "#@markdown **半精度训练**：通过混合了float16精度的训练方式减小显存占用以支持更大的批处理量\n",
        "FP16_Run: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **评估间隔**：每次保存模型所间隔的step数\n",
        "Eval_Interval: int = 1000   #@param {type:\"integer\"}\n",
        "#@markdown **输出目录**：用于存放生成的模型和配置文件的目录，若目录中已存在模型则会将其视为检查点（注意：当目录中存在多个模型时，编号最大的会被选为检查点）\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/模型训练结果/VITS/{date.today()}'   #@param {type:\"string\"}\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Start TensorBoard\n",
        "%tensorboard --logdir /content/drive/MyDrive/EVT/TrainResult\n",
        "\n",
        "PreprocessandTrain = train(\n",
        "    FileList_Path_Training,\n",
        "    FileList_Path_Validation,\n",
        "    Eval_Interval,\n",
        "    Epochs,\n",
        "    Batch_Size,\n",
        "    FP16_Run,\n",
        "    Keep_Original_Speakers,\n",
        "    Config_Path_Load,\n",
        "    Num_Workers,\n",
        "    Use_PretrainedModels,\n",
        "    Model_Path_Pretrained_G if Model_Path_Pretrained_G != \"None\" else None,\n",
        "    Model_Path_Pretrained_D if Model_Path_Pretrained_D != \"None\" else None,\n",
        "    Path(Output_Dir).parent.__str__(),\n",
        "    Path(Output_Dir).name,\n",
        "    \"/content/drive/MyDrive/EVT/log\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VITS2语音合成 VoiceConverter - VITS2\n",
        "将文字转为语音并生成音频文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.VITS.infer import infer\n",
        "\n",
        "#@markdown **配置加载路径**：该路径对应的配置文件会用于推理\n",
        "Config_Path_Load: str = '/content/drive/MyDrive/%EVT/模型训练结果/VITS/Config.json%'   #@param {type:\"string\"}\n",
        "#@markdown **G模型加载路径**：用于推理的生成器（Generator）模型所在路径\n",
        "Model_Path_Load: str = '/content/drive/MyDrive/%EVT/模型训练结果/VITS/G_*.pth%'   #@param {type:\"string\"}\n",
        "#@markdown **输入文字**：输入的文字会作为说话人的语音内容\n",
        "Text: str = '请输入语句'   #@param {type:\"string\"}\n",
        "#@markdown **所用语言**：说话人/文字所使用的语言，若使用自动检测则保持'None'即可\n",
        "Language: str = '[ZH]'   #@param [\"None\", \"[ZH]\", \"[EN]\", \"[JA]\"]\n",
        "#@markdown **人物名字**：说话人物的名字\n",
        "Speaker: str = '%Name%'   #@param {type:\"string\"}\n",
        "#@markdown **情感强度**：情感的变化程度\n",
        "EmotionStrength: float = .667   #@param {type:\"number\"}\n",
        "#@markdown **音素音长**：音素的发音长度\n",
        "PhonemeDuration: float = 0.8   #@param {type:\"number\"}\n",
        "#@markdown **整体语速**：整体的说话速度\n",
        "SpeechRate: float = 1.0   #@param {type:\"number\"}\n",
        "#@markdown **音频保存路径**：用于保存推理得到的音频的路径\n",
        "Audio_Path_Save: str = f'/content/drive/MyDrive/EVT/语音合成结果/VITS/{date.today()}.wav'   #@param {type:\"string\"}\n",
        "\n",
        "VoiceConverting = infer(\n",
        "    Config_Path_Load,\n",
        "    Model_Path_Load,\n",
        "    Text,\n",
        "    Language,\n",
        "    Speaker,\n",
        "    EmotionStrength,\n",
        "    PhonemeDuration,\n",
        "    SpeechRate,\n",
        "    Audio_Path_Save\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
