{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Colab"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 找到上方菜单栏“代码执行程序”——>弹窗底部“更改运行时类型”，选择GPU作为硬件加速器"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EblwyDLicmnp"
      },
      "source": [
        "\n",
        "\n",
        "- 防止断开连接：按住 Ctrl+Shift 再按下 I 呼出弹窗，于控制台内输入以下内容并回车：\n",
        "```\n",
        "function ConnectButton()\n",
        "{\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "```\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mount Google Drive for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get update``\n",
        "!sudo apt install portaudio19-dev\n",
        "%cd drive/MyDrive/Easy Voice Toolkit\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%cd /content/drive/MyDrive/Easy Voice Toolkit\n",
        "\n",
        "#import os\n",
        "from typing import Optional"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool_AudioProcessor\n",
        "该工具会将媒体文件批量转换为音频文件然后自动切除音频的静音部分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import sys\n",
        "#sys.path.append(os.path.join(os.getcwd(), \"Tool_AudioProcessor\"))\n",
        "\n",
        "from Tool_AudioProcessor.Process import Audio_Processing\n",
        "\n",
        "class Execute_Audio_Processing:\n",
        "    '''\n",
        "    Change media format to WAV and cut off the silent parts\n",
        "    '''\n",
        "    Media_Dir_Input: str = ''   # 媒体输入目录\n",
        "    Media_Dir_Output: str = ''   # 媒体输出目录\n",
        "    Media_Format_Output: str = 'wav'   # 媒体输出格式 choices = ['mp3', 'wav', ...]\n",
        "    RMS_Threshold: float = -40.   # 均方根阈值 (db)\n",
        "    Audio_Length_Min: int = 5000   # 最小音频长度 (ms)\n",
        "    Silent_Interval_Min: int = 300   # 最小静音间隔 (ms)\n",
        "    Hop_Size: int = 10   # 跳跃大小 (ms)\n",
        "    Silence_Kept_Max: int = 1000   # 最大静音长度 (ms)\n",
        "\n",
        "    def Run():\n",
        "        AudioConvertandSlice = Audio_Processing(\n",
        "            Execute_Audio_Processing.Media_Dir_Input,\n",
        "            Execute_Audio_Processing.Media_Dir_Output,\n",
        "            Execute_Audio_Processing.Media_Format_Output,\n",
        "            Execute_Audio_Processing.RMS_Threshold,\n",
        "            Execute_Audio_Processing.Audio_Length_Min,\n",
        "            Execute_Audio_Processing.Silent_Interval_Min,\n",
        "            Execute_Audio_Processing.Hop_Size,\n",
        "            Execute_Audio_Processing.Silence_Kept_Max\n",
        "        )\n",
        "        AudioConvertandSlice.Convert_Media()\n",
        "        AudioConvertandSlice.Slice_Audio()\n",
        "\n",
        "Execute_Audio_Processing.Run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool_VoiceIdentifier\n",
        "该工具会在不同说话人的音频中批量筛选出属于同一说话人的音频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import sys\n",
        "#sys.path.append(os.path.join(os.getcwd(), 'Tool_VoiceIdentifier'))\n",
        "\n",
        "from Tool_VoiceIdentifier.Identify import Voice_Identifying\n",
        "\n",
        "class Execute_Voice_Identifying:\n",
        "    '''\n",
        "    Contrast the voice and filter out the similar ones\n",
        "    '''\n",
        "    Audio_Path_Std: str = ''   # 标准音频路径\n",
        "    Audio_Dir_Input: str = ''   # 音频输入目录\n",
        "    Model_Dir: str = ''   # 模型存放目录\n",
        "    Model_Type: str = 'Ecapa-Tdnn'   # 模型类型 choices = ['Ecapa-Tdnn']\n",
        "    Model_Name: str = 'small'   # 模型名字 choices = ['small']\n",
        "    Feature_Method: str = 'spectrogram'   # 特征提取方法 choices = ['spectrogram', 'melspectrogram']\n",
        "    DecisionThreshold: float = 0.84   # 判断阈值 Recommanded\n",
        "    Duration_of_Audio: float = 3.00   # 音频长度 Recommanded\n",
        "\n",
        "    def Run():\n",
        "        AudioContrastInference = Voice_Identifying(\n",
        "            Execute_Voice_Identifying.Audio_Path_Std,\n",
        "            Execute_Voice_Identifying.Audio_Dir_Input,\n",
        "            Execute_Voice_Identifying.Audio_Dir_Output,\n",
        "            Execute_Voice_Identifying.Model_Dir,\n",
        "            Execute_Voice_Identifying.Model_Type,\n",
        "            Execute_Voice_Identifying.Model_Name,\n",
        "            Execute_Voice_Identifying.Feature_Method,\n",
        "            Execute_Voice_Identifying.DecisionThreshold,\n",
        "            Execute_Voice_Identifying.Duration_of_Audio\n",
        "        )\n",
        "        AudioContrastInference.GetModel()\n",
        "        AudioContrastInference.Inference()\n",
        "\n",
        "Execute_Voice_Identifying.Run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool_VoiceTranscriber\n",
        "该工具会将语音文件的内容批量转换为带时间戳的文本并以字幕文件的形式保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import sys\n",
        "#sys.path.append(os.path.join(os.getcwd(), 'Tool_VoiceTranscriber'))\n",
        "\n",
        "from Tool_VoiceTranscriber.Transcribe import Voice_Transcribing\n",
        "\n",
        "class Execute_Voice_Transcribing:\n",
        "    '''\n",
        "    Transcribe WAV content to SRT\n",
        "    '''\n",
        "    Model_Name: str = 'small'   # 模型名字 choices = ['tiny', 'base', 'small', 'medium', 'large']\n",
        "    Model_Dir: str = ''   # 模型存放目录\n",
        "    WAV_Dir: str = ''   # 音频目录\n",
        "    SRT_Dir: str = ''   # 字幕输出目录\n",
        "    Verbose: bool = True   # 启用输出日志\n",
        "    Language: Optional[str] = None   # 所用语言 choices = ['zh', 'en', ..., None]\n",
        "    Condition_on_Previous_Text: bool = True   # 前后文一致\n",
        "    fp16: bool = True   # 半精度训练\n",
        "\n",
        "    def Run():\n",
        "        WAVtoSRT = Voice_Transcribing(\n",
        "            Execute_Voice_Transcribing.Model_Name,\n",
        "            Execute_Voice_Transcribing.Model_Dir,\n",
        "            Execute_Voice_Transcribing.WAV_Dir,\n",
        "            Execute_Voice_Transcribing.SRT_Dir,\n",
        "            Execute_Voice_Transcribing.Verbose,\n",
        "            Execute_Voice_Transcribing.Language,\n",
        "            Execute_Voice_Transcribing.Condition_on_Previous_Text,\n",
        "            Execute_Voice_Transcribing.fp16\n",
        "        )\n",
        "        WAVtoSRT.Transcriber()\n",
        "\n",
        "Execute_Voice_Transcribing.Run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool_DatasetCreator\n",
        "该工具会生成适用于语音模型训练的数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import sys\n",
        "#sys.path.append(os.path.join(os.getcwd(), 'Tool_DatasetCreator'))\n",
        "\n",
        "from Tool_DatasetCreator.Create import Dataset_Creating\n",
        "\n",
        "class Execute_Dataset_Creating:\n",
        "    '''\n",
        "    Convert the whisper-generated SRT to CSV and split the WAV\n",
        "    '''\n",
        "    SRT_Dir: str = ''   #Execute_Voice_Transcribing.SRT_Dir\n",
        "    WAV_Dir: str = ''   # 音频输入目录\n",
        "    Sample_Rate: int = 22050   # 采样率 (HZ)\n",
        "    Subtype: str = 'PCM_16'   # 采样格式\n",
        "    WAV_Dir_Split: str = ''   # 音频输出目录\n",
        "    Encoder: str = 'VITS'   # 自编码器 choices = ['VITS']\n",
        "    IsSpeakerMultiple: bool = False   # 是否多人\n",
        "    FileList_Path_Training: str = ''   # 训练集文本路径\n",
        "    FileList_Path_Validation: str = ''   # 验证集文本路径\n",
        "\n",
        "    def Run():\n",
        "        SRTtoCSVandSplitAudio = Dataset_Creating(\n",
        "            Execute_Dataset_Creating.SRT_Dir,\n",
        "            Execute_Dataset_Creating.WAV_Dir,\n",
        "            Execute_Dataset_Creating.Sample_Rate,\n",
        "            Execute_Dataset_Creating.Subtype,\n",
        "            Execute_Dataset_Creating.WAV_Dir_Split,\n",
        "            Execute_Dataset_Creating.Encoder,\n",
        "            Execute_Dataset_Creating.IsSpeakerMultiple,\n",
        "            Execute_Dataset_Creating.FileList_Path_Training,\n",
        "            Execute_Dataset_Creating.FileList_Path_Validation\n",
        "        )\n",
        "        SRTtoCSVandSplitAudio.CallingFunctions()\n",
        "\n",
        "Execute_Dataset_Creating.Run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool_VoiceEncoder\n",
        "该工具会训练出适用于语音合成的模型文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import sys\n",
        "#sys.path.append(os.path.join(os.getcwd(), 'Tool_VoiceEncoder'))\n",
        "\n",
        "from Tool_VoiceEncoder.Encode import Voice_Encoding\n",
        "\n",
        "class Execute_Voice_Encoding:\n",
        "    '''\n",
        "    Preprocess and then start training\n",
        "    '''\n",
        "    FileList_Path_Validation: str = ''   # 训练集文本路径\n",
        "    FileList_Path_Training: str = ''   # 验证集文本路径\n",
        "    Language: str = 'chinese'   # 所用语言\n",
        "    Config_Path_Load: Optional[str] = None   # 配置加载路径\n",
        "    Config_Dir_Save: str = ''   # 配置保存目录\n",
        "    Eval_Interval: int = 1000   # 保存间隔\n",
        "    Epochs: int = 10000   # 迭代次数\n",
        "    Batch_Size: int = 8   # 批处理量 choices = [Power of 2]\n",
        "    FP16_Run: bool = True   # 半精度训练\n",
        "    IsSpeakerMultiple: bool = False   # 是否多人\n",
        "    N_Speakers: int = 0   # 说话人数\n",
        "    Speakers: list = ['']   # 人物名字 format = ['%SpeakerName1%', '%SpeakerName2%', ...]\n",
        "    Num_Workers: int = 8   # 进程数量\n",
        "    Model_Path_Pretrained_G: Optional[str] = None   # 预训练G模型路径\n",
        "    Model_Path_Pretrained_D: Optional[str] = None   # 预训练D模型路径\n",
        "    Model_Dir_Save: str = ''   # 模型保存目录\n",
        "    Model_Name_Save: str = ''   # 模型保存名字\n",
        "    \n",
        "    def Run():\n",
        "        PreprocessandTrain = Voice_Encoding(\n",
        "            Execute_Voice_Encoding.FileList_Path_Validation,\n",
        "            Execute_Voice_Encoding.FileList_Path_Training,\n",
        "            Execute_Voice_Encoding.Language,\n",
        "            Execute_Voice_Encoding.Config_Path_Load,\n",
        "            Execute_Voice_Encoding.Config_Dir_Save,\n",
        "            Execute_Voice_Encoding.Eval_Interval,\n",
        "            Execute_Voice_Encoding.Epochs,\n",
        "            Execute_Voice_Encoding.Batch_Size,\n",
        "            Execute_Voice_Encoding.FP16_Run,\n",
        "            Execute_Voice_Encoding.IsSpeakerMultiple,\n",
        "            Execute_Voice_Encoding.N_Speakers,\n",
        "            Execute_Voice_Encoding.Speakers,\n",
        "            Execute_Voice_Encoding.Num_Workers,\n",
        "            Execute_Voice_Encoding.Model_Path_Pretrained_G,\n",
        "            Execute_Voice_Encoding.Model_Path_Pretrained_D,\n",
        "            Execute_Voice_Encoding.Model_Dir_Save,\n",
        "            Execute_Voice_Encoding.Model_Name_Save\n",
        "        )\n",
        "        PreprocessandTrain.Preprocessing_and_Training()\n",
        "\n",
        "Execute_Voice_Encoding.Run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "My_Env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "d638444b7179bdfc0dc1957817588c7007ff4b9946fa53f9cc2df304cc8f4127"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
